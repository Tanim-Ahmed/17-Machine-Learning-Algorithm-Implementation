# -*- coding: utf-8 -*-
"""Machine Learning Algorithm.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TL3WvRbzM6P-DM-Hli7I_sOPDDcMNup8
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from sklearn.linear_model import LinearRegression
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from scipy import stats
import pylab as pl

data = pd.read_csv('Iris.csv')

data = pd.read_csv('Iris.csv')

data = pd.read_csv('Iris.csv')

data = pd.read_csv('Iris.csv')

data.head()

print(data.shape)

data.head()

data.tail()

data.head()

data.shape

data.shape

data.info

data.info()

data.shape

data.isnull()

sns.FacetGrid(data,hue='Id',size=5)\
.map(plt.scatter,'SepalLengthCm','SepalWidthCm')\
.add_legend()

sns.FacetGrid(data,hue='Species',size=5)\
.map(plt.scatter,'SepalLengthCm','SepalWidthCm')\
.add_legend()

sns.pairplot(data,hue='Id')

X = data.iloc[:,:-1].values

print(X)

y  = data.iloc[:,-1].values

print(y)

X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state = 0)

XL = data.iloc[:,:-1].values
yl = data.iloc[:,-1]

print(yl)

print(XL)

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
Y_train = le.fit_transform(yl)

print(Y_train)

data.head

X_trainL,X_testL,y_trainL,y_testL = train_test_split(XL,Y_train,test_size=0.3,random_state=0 )

############*******Linear Regression***********#############
from sklearn.linear_model import LinearRegression
from sklearn import metrics
modelLR = LinearRegression()
modelLR.fit(X_trainL,y_trainL)
Y_pred = modelLR.predict(X_testL)
print(modelLR.intercept_)
print(modelLR.coef_)
print(metrics.mean_absolute_error(y_testL,Y_pred))
print('Mean Abs Error MAE      :' ,metrics.mean_absolute_error(y_testL,Y_pred))
print('Mean Sqrt Error MSE     :' ,metrics.mean_squared_error(y_testL,Y_pred))
print('Root Mean Sqrt Error RMSE:' ,np.sqrt(metrics.mean_squared_error(y_testL,Y_pred)))
print('r2 value                :' ,metrics.r2_score(y_testL,Y_pred))

######**********Decision Tree************######
from sklearn.tree import DecisionTreeClassifier
Model = DecisionTreeClassifier()
Model.fit(X_train,y_train)
y_pred = Model.predict(X_test)
print("Classification Report:\n")
print(classification_report(y_test,y_pred))
print("Confusion Matrix:\n")
print(confusion_matrix(y_test,y_pred))
print("Accuracy Report\n")
print('Accuracy is',accuracy_score(y_pred,y_test)*100)

######**********Random Forest Classifier************######
from sklearn.ensemble import RandomForestClassifier
Model = RandomForestClassifier(max_depth=3)
Model.fit(X_train,y_train)
y_pred = Model.predict(X_test)
print("Classification Report:\n")
print(classification_report(y_test,y_pred))
print("Confusion Matrix\n")
print(confusion_matrix(y_pred,y_test))
print("Accuracy\n")
print(accuracy_score(y_pred,y_test)*100)

#########Logistic Regression########
from sklearn.linear_model import LogisticRegression
Model = LogisticRegression()
Model.fit(X_train,y_train)
y_pred = Model.predict(X_test)
print("Classification Report\n")
print(classification_report(y_test,y_pred))
print("Confusion Matrix\n")
print(confusion_matrix(y_test,y_pred))
print("Accuracy Score")
print(accuracy_score(y_test,y_pred))

from sklearn.linear_model import LogisticRegression
Model = LogisticRegression()
Model.fit(X_train,y_train)
y_pred = Model.predict(X_test)
print(classification_report(y_pred,y_test))
print(confusion_matrix(y_pred,y_test))
print(accuracy_score(y_pred,y_test))

from sklearn.ensemble import RandomForestClassifier
Model = RandomForestClassifier(max_depth = 2)
Model.fit(X_train,y_train)
y_pred = Model.predict(X_test)
print(classification_report(y_pred,y_test))
print(confusion_matrix(y_pred,y_test))
print(accuracy_score(y_pred,y_test))

######**********K Nearest Neighbors**********#######
from sklearn.neighbors import KNeighborsClassifier
Model = KNeighborsClassifier(n_neighbors = 8)
Model.fit(X_train,y_train)
y_pred = Model.predict(X_test)
print("Classification Report:")
print(classification_report(y_pred,y_test))
print("Confusion Matrix:\n")
print(confusion_matrix(y_pred,y_test))
print(accuracy_score(y_pred,y_test))

######*********** Naive Bayes********##
from sklearn.naive_bayes import GaussianNB
Model =  GaussianNB()
Model.fit(X_train,y_train)
y_pred = Model.predict(X_test)
print("Classification Report:")
print(classification_report(y_pred,y_test))
print("Confusion Matrix\n")
print(confusion_matrix(y_pred,y_test))
print("Accuracy Score\n")
print(accuracy_score(y_pred,y_test))

#########********** SVM*****************######
from sklearn.svm import SVC
Model = SVC()
Model.fit(X_train,y_train)
y_pred = Model.predict(X_test)

from sklearn.svm import SVC
Model = SVC()
Model.fit(X_train,y_train)
y_pred = Model.predict(X_test)

print("Classification Report")
print(classification_report(y_pred,y_test))
print("Confusion Matrix")
print(confusion_matrix(y_pred,y_test))
print(accuracy_score(y_pred,y_test))

########### Radius Neighbors Classifier****########
from sklearn.neighbors import RadiusNeighborsClassifier
Model = RadiusNeighborsClassifier(radius = 8.0)
Model.fit(X_train,y_train)
y_pred = Model.predict(X_test)
print(classification_report(y_pred,y_test))
print(confusion_matrix(y_pred,y_test))
print(accuracy_score(y_pred,y_test))

###########Passive Aggressive Classifier********#######
from sklearn.linear_model import PassiveAggressiveClassifier
Model = PassiveAggressiveClassifier()
Model.fit(X_train,y_train)
y_pred = Model.predict(X_test)
print("Classification Report")
print(classification_report(y_pred,y_test))
print("Confusion Matrix\n")
print(confusion_matrix(y_pred,y_test))
print("Accuracy Score")
print(accuracy_score(y_pred,y_test))

########BernoulliNB################
from sklearn.naive_bayes import BernoulliNB
Model =  BernoulliNB()
Model.fit(X_train,y_train)
y_pred = Model.predict(X_test)
print("Classification Report")
print(classification_report(y_pred,y_test))
print("Confusion Matrix")
print(confusion_matrix(y_pred,y_test))
print("Accuracy Score")
print(accuracy_score(y_pred,y_test))

#######ExtraTreeClassifier#########

from sklearn.tree import ExtraTreeClassifier
Model = ExtraTreeClassifier()
Model.fit(X_train,y_train)
y_pred = Model.predict(X_test)
print("Classification Report")
print(classification_report(y_pred,y_test))
print("Confusion Matrix")
print(confusion_matrix(y_pred,y_test))
print("Accuracy")
print(accuracy_score(y_pred,y_test))

############Bagging############
from sklearn.ensemble import BaggingClassifier
Model = BaggingClassifier()
Model.fit(X_train,y_train)
y_pred=Model.predict(X_test)

# Summary of the predictions made by the classifier
print(classification_report(y_test,y_pred))
print(confusion_matrix(y_pred,y_test))

#Accuracy Score
print('accuracy is ',accuracy_score(y_pred,y_test))

#############AdaBoostClassifier##############
from sklearn.ensemble import AdaBoostClassifier
Model = AdaBoostClassifier()
Model.fit(X_train,y_train)
y_pred = Model.predict(X_test)
print("Classification Report")
print(classification_report(y_test,y_pred))
print("Confusion Matrix")
print(confusion_matrix(y_pred,y_test))
print("Accuracy")
print(accuracy_score(y_pred,y_test))

from sklearn.ensemble import GradientBoostingClassifier
Model = GradientBoostingClassifier()
Model.fit(X_train,y_train)
y_pred = Model.predict(X_test)
print("Classificatoin Report")
print(classification_report(y_pred,y_test))
print("Confusion Matrix")
print(confusion_matrix(y_pred,y_test))
print("Accuracy")
print(accuracy_score(y_pred,y_test))

#########Linear Discriminant############
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
Model = LinearDiscriminantAnalysis()
Model.fit(X_train,y_train)
y_pred = Model.predict(X_test)
print("Classification Report")
print(classification_report(y_pred,y_test))
print("Confusion Matrix")
print(confusion_matrix(y_pred,y_test))
print("Accuracy score")
print(accuracy_score(y_pred,y_test))

###########Quadratic Discriminant Analysis##########
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
Model = QuadraticDiscriminantAnalysis()
Model.fit(X_train,y_train)
y_pred = Model.predict(X_test)
print("Classification Report")
print(classification_report(y_test,y_pred))
print("Confusion Matrix")
print(confusion_matrix(y_pred,y_test))
print("Accuracy")
print(accuracy_score(y_pred,y_test))

########K means #########
x = data.iloc[:,[1,2,3,4]].values
from sklearn.cluster import KMeans
wcss = []
for i in range(1, 11):
    kmeans = KMeans(n_clusters = i, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)
    kmeans.fit(x)
    wcss.append(kmeans.inertia_)
    
#Plotting the results onto a line graph, allowing us to observe 'The elbow'
plt.plot(range(1, 11), wcss)
plt.title('The elbow method')
plt.xlabel('Number of clusters')
plt.ylabel('WCSS') # within cluster sum of squares
plt.show()

#Applying kmeans to the dataset / Creating the kmeans classifier
kmeans = KMeans(n_clusters = 3, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)
y_kmeans = kmeans.fit_predict(x)
#Visualising the clusters

plt.scatter(x[y_kmeans == 0, 0], x[y_kmeans == 0, 1], s = 100, c = 'red', label = 'Iris-Setosa')
plt.scatter(x[y_kmeans == 1, 0], x[y_kmeans == 1, 1], s = 100, c = 'blue', label = 'Iris-Versicolour')
plt.scatter(x[y_kmeans == 2, 0], x[y_kmeans == 2, 1], s = 100, c = 'yellow', label = 'Iris-Virginica')

#Plotting the centroids of the clusters
plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:,1], s = 100, c = 'green', label = 'Centroids',marker='*')

plt.legend()